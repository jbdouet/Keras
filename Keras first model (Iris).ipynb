{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras first model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to get used to Keras to understand well how it works, in fine I'd like to be able to build a model using LSTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install keras on a mac, it is necessary to modify the tensorflow_backend file \n",
    "and replace the line after the importError exception with <br /> \"from tensorflow.python.ops import nn  as ctc\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default keras will work using Tensorflow, it is possible though to make it use Theano, here is how: https://keras.io/backend/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As found here:http://machinelearningmastery.com/introduction-python-deep-learning-library-keras/ <br />\n",
    "The principle to build a model with keras are: <br />\n",
    "0) Get the data <br />\n",
    "1) Define your model. Create a sequence and add layers.<br />\n",
    "2) Compile your model. Specify loss functions and optimizers.<br />\n",
    "3) Fit your model. Execute the model using data.<br />\n",
    "4) Make predictions. Use the model to generate predictions on new data.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work on the iris dataset, that can be downloaded directly from scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "# import the data\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =iris.data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the data is not stratified !\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 5.1,  3.5,  1.4,  0.2]), 0), (array([ 4.9,  3. ,  1.4,  0.2]), 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(X[i],y[i]) for i,x in enumerate(y)]\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 6.1,  2.8,  4. ,  1.3]), 1), (array([ 4.5,  2.3,  1.3,  0.3]), 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle(data)\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newX= [x[0].tolist() for x in data]\n",
    "newY=  [x[1].tolist() for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_binary = to_categorical(newY)\n",
    "# that transforms the integers in 1-hot vectors like [1,0,0], [0,1,0], [0,0,1] in our case \n",
    "y_binary[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final sets\n",
    "seperator = len(newX)*8/10\n",
    "Xtraining=newX[:seperator]\n",
    "Xtest= newX[seperator:]\n",
    "Ytraining= y_binary[:seperator]\n",
    "Ytest= y_binary[seperator:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Xtraining= np.array(Xtraining)\n",
    "Xtest= np.array(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential() # creates the sequence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here it is possible to add any kind and number of layers to the sequence using the .add() method.<br />\n",
    "Some documentation about Keras layers can be found here https://keras.io/layers/about-keras-layers/ as well as the different types of layers <br />\n",
    "We will deal with some of those models but the important thing is to thoroughly consult the documentation as the sequences can also be used for normalizing, word embedding, merging vectors and not only create the network. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset is quite small we will use a 1-layer neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we are adding a fully connected hidden layer, with 10 neurons.\n",
    "model.add(Dense(10, input_dim=4,init='uniform', activation='relu'))\n",
    "# here is our output layer\n",
    "model.add(Dense(3, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fa95a669a4e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','precision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is the first model with keras, here is a vocabulary clarification I found on stackoverflow:<br />\n",
    "In the neural network terminology:<br />\n",
    "one <b>epoch</b> = one forward pass and one backward pass of all the training examples<br />\n",
    "<b>batch size </b>= the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.<br />\n",
    "number of <b>iterations</b> = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes).<br />\n",
    "Example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x109d2ea10>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to see the results for each epoch we can set verbose to 1 or not precise it as 1 is the default value.\n",
    "# Here, I don't want to display it for practical reasons.\n",
    "model.fit(Xtraining, Ytraining, nb_epoch=150, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "# we can make predictions on the test set with our newly trained model\n",
    "classes = model.predict_classes(Xtest, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(Xtest, Ytest, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46102365851402283, 0.96666663885116577]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 96.67%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], loss_and_metrics[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "acc: 96.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
